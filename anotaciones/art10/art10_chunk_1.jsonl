{"id":1,"text":"Data and text mining BioBERT : a pre-trained biomedical language representation model for biomedical text mining Jinhyuk Lee 1, †, Wonjin Yoon 1, †, Sungdong Kim 2, Donghyeon Kim 1, Sunkyu Kim 1, Chan Ho So 3 and Jaewoo Kang 1, 3, * 1Department of Computer Science and Engineering, Korea University, Seoul 02841, Korea, 2Clova AI Research, Naver Corp, Seong-Nam 13561, Korea and 3Interdisciplinary Graduate Program in Bioinformatics, Korea University, Seoul 02841, Korea * To whom correspondence should be addressed. † The authors wish it to be known that the first two authors contributed equally. Associate Editor : Jonathan Wren Received on May 16, 2019 ; revised on July 29, 2019 ; editorial decision on August 25, 2019 ; accepted on September 5, 2019 Abstract Motivation : Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing ( NLP ), extracting valuable information from bio-medical literature has gained popularity among researchers, and deep learning has boosted the development of ef-fective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text min-ing often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora. Results : We introduce BioBERT ( Bidirectional Encoder Representations from Transformers for Biomedical Text Mining ), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks : biomedical named entity recognition ( 0. 62 % F1 score improvement ), bio","label":[[21,28,"MODEL"],[1491,1498,"MODEL"],[1739,1746,"MODEL"],[1981,1988,"MODEL"],[1424,1428,"MODEL"],[1767,1771,"MODEL"],[1900,1904,"MODEL"],[1052,1065,"TECHNIQUE"],[2135,2143,"TECHNIQUE"],[90,112,"APPLICATION"],[778,800,"APPLICATION"],[1108,1130,"APPLICATION"],[1561,1583,"APPLICATION"],[1825,1847,"APPLICATION"],[2058,2080,"APPLICATION"],[1544,1556,"TECHNOLOGY"]],"Comments":[]}
