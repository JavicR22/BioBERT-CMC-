{"id":3,"text":"but also scarce, as detailed in the study on integrated DL and NLP for continuous remote monitoring, While traditional DL models like BERT have facilitated advancements, their reliance on extensive fine-tuning, which demands labeled data and significant com-putational resources, limits their practical deployment. In contrast, GPT-3. 5 offers a more streamlined approach with OpenAI ’ s ready-to-use API, simplifying integration into existing systems without the need for extensive infrastruc-ture setup. Despite these advancements, DL models in pathology report analysis often face challenges related to the need for extensive labeled datasets, which are expensive and time-consuming to create. Additionally, DL models can strug-gle with the variability of medical terminology and the idi-osyncrasies of report formats, which can vary widely across institutions and languages. These challenges highlight the difficulty of applying such models universally in clini-cal practice, where adaptability and accuracy are crucial [ 10 – 12 ]. BERT utilizes a transformer encoder architecture focused on bidirectional context processing, which, while robust for short texts, often struggles with the coherent generation of long-form content. Conversely, GPT-3. 5 employs a trans-former decoder architecture, enhancing its capability to generate extensive, contextually rich text, better suiting the complex narratives found in pathology reports. There is an urgent need for an automated solution that can efficiently structure unstructured pathology reports, enhanc-ing data accuracy and accessibility. This solution must be scalable, capable of adapting to various types of pathology reports and robust enough to support global interoperability. The ability to convert free text into structured data system-atically would revolutionize pathological data analysis, ena-bling more sophisticated research and improved healthcare outcomes worldwide. The introduction of Generative AI, particularly through the use of advanced Large Language Models ( LLMs ) like GPT, offers a transformative solution to these challenges. Furthermore, GPT-3. 5 ’ s versatility allows it to excel across a broad range of NLP tasks without the need for domain-specific tuning, unlike BERT which requires versions like BioBERT for optimized performance in medi-cal contexts. Additionally, GPT-3. 5's user-friendly design accepts natural language prompts and delivers direct,","label":[[1053,1064,"MODEL"],[1266,1278,"MODEL"],[2288,2295,"MODEL"],[1392,1399,"MODEL"],[328,333,"MODEL"],[1247,1252,"MODEL"],[2124,2129,"MODEL"],[2358,2363,"MODEL"],[134,138,"MODEL"],[1037,1041,"MODEL"],[2254,2258,"MODEL"],[2052,2055,"MODEL"],[198,209,"TECHNIQUE"],[89,99,"TECHNIQUE"],[1003,1011,"METRIC"],[1568,1576,"METRIC"],[1420,1437,"TECHNOLOGY"],[1533,1550,"TECHNOLOGY"],[1668,1685,"TECHNOLOGY"]],"Comments":[]}
