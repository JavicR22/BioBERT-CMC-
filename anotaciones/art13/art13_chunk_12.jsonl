{"id":12,"text":"plays a vital role in mitigating the knowledge-forgetting issue during pre-training2, 9. However, determining the optimal balance between general domain data and spe-cialized medical data is nontrivial, requiring careful empirical analysis. Future studies should examine methods to better determine the opti-mal ratio. The cost-effectiveness of instruction tuning is another important consideration. Pre-training, exemplified by the LLaMA2 70B model, is notably resource-heavy, requiring about 160 * 700 GPU hours per epoch. Conversely, instruction tuning is far less resource-demanding, needing roughly 8 * 70 GPU hours per epoch, making it much more affordable than pre-training. While continual pre-training aims to incorporate specialized medical knowledge into the model, the observed performance improve-ments, particularly for smaller models like Me-LLaMA 13B, are relatively modest. This limited improvement can be attributed to several factors. First, theamountofdomain-specificpre-trainingdatausedissignificantlysmaller compared to the original pre-training data of LLaMA2, which exceeds 2 T tokens. This discrepancy suggests that larger amounts of domain-specific data may be required to fully activate the model â€™ s potential. Second, the continual pre-training strategy itself could be optimized further. As noted earlier, the process faces challenges such as catastrophic forgetting, where themodellosesgeneral-domainknowledgeduringadaptationtospecialized data. Despite this, models trained only with the instruction tuning demonstrate that instruction tuning alone can significantly enhance per-formance at a fraction of the computational cost. This highlights instruction tuning as a practical and cost-effective alternative, particularly in scenarios where computational resources are limited. The Me-LLaMA models, available in both 13B and 70B sizes, as well as in base and chat-optimized versions, enable a wide array of medical appli-cations, guided by the crucial balance between model size and resource availability. The base models provide a strong foundation for supervised fine-tuning on specialized tasks, while the chat-optimized versions excel in instruction-following and zero-shot scenarios. Larger models, like the 70B, deliver superior reasoning capabilities but require significant computational resources,","label":[[857,862,"MODEL"],[1818,1823,"MODEL"],[433,439,"MODEL"],[345,363,"TECHNIQUE"],[537,555,"TECHNIQUE"],[1519,1537,"TECHNIQUE"],[1555,1573,"TECHNIQUE"],[1676,1694,"TECHNIQUE"],[2098,2109,"TECHNIQUE"]],"Comments":[]}
