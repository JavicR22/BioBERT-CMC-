{"id":5,"text":"##competitivewith LLaMA2 70B and Meditron 70B, which have significantly larger parameter sizes, on 8 out of 12 datasets. As for 70B models, Me-LLaMA 70B achieved the best performance on 9 out of 12 datasets, when benchmarked against LLaMA2 70B and Meditron 70B. shows the zero-shot performance of Me-LLaMA chat models and other instruction-tuned open LLMs with chat ability on various tasks. Among 13B models, Me-LLaMA 13B-chat outperformed LLaMA2 13B-chat, PMC-LLaMA-chat, Medalpaca 13B in almost all 12 datasets. Me-LLaMA outperformed AlpaCare-13B in 9 out of 12 datasets. Among models with 70B parameters, Me-LLaMA 70B-chat consistently outperformed LLaMA2-70B-chat on 11 out of 12 datasets. It is worth noting that Me-LLaMA13B-chat showed better performance than LLaMA2-70B-chat-a model with a significantly larger parameter size-on 6outof12datasetsandwascompetitivewiththeLLaMA2-70B-chatin3out of 6 remaining datasets. zero-shot and supervised learning setting, against ChatGPT and GPT-4. Due to privacy concerns, which preclude the transmission of clinical datasets with patient information to ChatGPT and GPT-4, we conducted our comparison across 8 datasets that are not subject to these limitations. The results of ChatGPTandGPT-4onthreeQAdatasetsarereferencedfromtheOpenAI ’ s The supervised fine-tuning performance of various open source LLMs on six tasks Task Dataset Metric LLaMA2 13B PMC-LLaMA 13B Me-LLaMA 13B LLaMA2 70B Meditron 70B Me-LLaMA 70B Question answering PubMedQA Acc 0. 800 0. 778 0. 802 0. 800 0. 800 0. 814 Macro-F1 0. 560 0. 544 0. 562 0. 560 – 0. 572 MedQA Acc 0. 467 0. 45","label":[[987,990,"MODEL"],[1112,1115,"MODEL"],[975,982,"MODEL"],[1100,1107,"MODEL"],[474,483,"MODEL"],[143,148,"MODEL"],[300,305,"MODEL"],[413,418,"MODEL"],[462,467,"MODEL"],[518,523,"MODEL"],[612,617,"MODEL"],[1401,1406,"MODEL"],[1414,1419,"MODEL"],[1451,1456,"MODEL"],[18,24,"MODEL"],[938,957,"TECHNIQUE"],[1301,1312,"TECHNIQUE"],[949,957,"TECHNIQUE"],[213,224,"TECHNIQUE"],[1461,1479,"APPLICATION"],[1480,1488,"DATASET"]],"Comments":[]}
