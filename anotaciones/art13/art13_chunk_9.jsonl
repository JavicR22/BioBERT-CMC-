{"id":9,"text":"in the field. Performance of complex clinical case diagnosis shows the top-K ( 1 K 5 ) accuracy of Me-LLaMA-70B-chat, ChatGPT, GPT-4, and LLaMA2-70B-chat, in the complex clinical case diagnosis task. We can see Me-LLaMA-70B-chat model achieved com-parable performance with GPT-4 and ChatGPT and significantly outper-forms LLaMA2-70B-chat. The human evaluation result in again shows that Me-LLaMA-70B-chat outperformed GPT-4 in both top-1 and top-5 accuracy. These results demonstrated the potential of Me-LLaMA models for challenging clinical applications. Impact of continual pretraining and instruction tuning demonstrates the impact of continual pre-training and instruction tuning on zero-shot performance across medical NLP tasks. It clearly demonstrates that both continual pre-training and instruction tuning sig-nificantly enhanced the zero-shot capabilities of models. Instruction tuning aloneprovidessignificantperformanceimprovementsoverthebaseLLaMA2 models, as seen in LLaMA2 13B, where accuracy on PubMedQA increases from0. 216 to 0. 436. This suggests that instruction tuning is highly effective in enhancing the model ’ s ability to follow task-specific prompts. In contrast, continual pre-training on medical data yields relatively modest improve-ments, particularly for smaller models. Me-LLaMA 13B shows only slight gains over LLaMA2 13B, likely due to the smaller scale of domain-specific pre-training data compared to LLaMA2 ’ s original training corpus, which exceeds 2 T tokens. Additionally, continual pre-training may not provide as strong of a task-specific signal as instruction tuning, limiting its impact in zero-shot settings. However, for larger models like Me-LLaMA 70B, con-tinual pre-training results in more notable improvements, with performance gains ranging from 2. 1 % to 55 % across various datasets, demonstrating its value in capturing specialized domain knowledge. The best results are con-sistently achieved when both continual pre-training and instruction tuning are","label":[[127,130,"MODEL"],[273,276,"MODEL"],[418,421,"MODEL"],[118,125,"MODEL"],[283,290,"MODEL"],[102,107,"MODEL"],[214,219,"MODEL"],[390,395,"MODEL"],[505,510,"MODEL"],[1306,1311,"MODEL"],[1691,1696,"MODEL"],[138,144,"MODEL"],[29,36,"MODEL"],[162,169,"MODEL"],[593,611,"TECHNIQUE"],[666,684,"TECHNIQUE"],[797,815,"TECHNIQUE"],[878,896,"TECHNIQUE"],[1071,1089,"TECHNIQUE"],[1593,1611,"TECHNIQUE"],[1988,2006,"TECHNIQUE"],[87,95,"METRIC"],[448,456,"METRIC"],[999,1007,"METRIC"],[442,456,"METRIC"],[1011,1019,"DATASET"]],"Comments":[]}
