{"id":21,"text":"Meditron7B / 70B9 : these are medical LLMs based on LLaMA2-7B / 70B, continually pre-trained with a mix of clinical guidelines, medical papers and abstracts. Zero-shot Learning We assessed our Me-LLaMA 13 / 70B-chat models ’ zero-shot learning cap-abilities, which are key for new task understanding and response without specific prior training. We compared our models and baseline models ’ zero-shot, using standardized prompts ( detailed in the Supplementary Infor-mation, Supplementary for each test dataset from We compared Me-LLaMA 13 / 70B-chat models with the following baseline models : ChatGPT / GPT-44 : SOTA commercialized LLMs. We used the version of \" gpt-3. 5-turbo-0301 \" for ChatGPT, and the version of \" gpt-4-0314 \" for GPT-4. LLaMA2-7B / 13B / 70B-chat6 models were adaptations of the LLaMA2 series, optimized for dialogue and conversational scenarios. Medalpaca-7B / 13B3 models were based on LLaMA-7B / 13B, specifically fine-tuned for tasks in the medical domain. The PMC-LLaMA-13B-chat2 model is an instruction-tuned medical LLM based on PMC-LLaMA-13B. The AlpaCare-13B11 model is specifically tailored for clinical tasks based on LLaMA-2 13B by instruction tuning. Meditron 70B9 is a medical LLM, continually pre-trained with a mix of clinical guidelines, biomedical papers, and abstracts based on LLaMA2 70B. Data availability All datasets employed in the continual pre-training process and evaluation are accessible from their original published venues. The PubMed Central and PubMed Abstracts subset from The Pile are available at https : / / huggingface. co / datasets / EleutherAI / pile. MIMIC-IV and MIMIC-CXR datasets can be accessed under the PhysioNet Credentialed Health Data Use Agreement 1. 5. 0 at https :","label":[[605,608,"MODEL"],[665,668,"MODEL"],[721,724,"MODEL"],[738,741,"MODEL"],[665,670,"MODEL"],[595,602,"MODEL"],[691,698,"MODEL"],[872,881,"MODEL"],[196,201,"MODEL"],[531,536,"MODEL"],[913,918,"MODEL"],[994,999,"MODEL"],[1065,1070,"MODEL"],[1154,1159,"MODEL"],[1154,1161,"MODEL"],[158,176,"TECHNIQUE"],[225,243,"TECHNIQUE"],[1169,1187,"TECHNIQUE"],[942,952,"TECHNIQUE"],[168,176,"TECHNIQUE"],[1484,1490,"DATASET"],[1503,1509,"DATASET"],[1618,1626,"DATASET"],[1631,1640,"DATASET"],[1618,1624,"DATASET"],[1631,1637,"DATASET"]],"Comments":[]}
