{"id":10,"text":", 2018 ) ; ShARe / CLEFE ( Leaman, 2015 ) ; DDI ( Zhang, 2018 ). Chem-Prot ( Peng, 2018 ) ; i2b2 ( Rink, 2011 ) ; HoC ( Du, 2019 ) ; MedNLI ( Romanov and Shivade, 2018 ). P : PubMed, P + M : PubMed + MIMIC-III Baseline performance on the BLUE task test sets. For named entity recognition, we used a Bi-LSTM-CRF implementation as a sequence tag-ger ( Huang, 2015 ; Si, 2019 ; Lample, 2016 ). Specifically, we concatenated the GloVe word embeddings ( Pennington, 2014 ), character embeddings, and ELMo embeddings of each token and fed the combined vectors into the sequence tagger to predict the label for each to-ken. The GloVe word embeddings11 and character embeddings have 100 and 25 dimensions, respec-tively. The hidden sizes of the Bi-LSTM are also set to 100 and 25 for the word and character em-beddings, respectively. For relation extraction and multi-label tasks, we followed the steps in fine-tuning with BERT but used the averaged ELMo embeddings of all words in each sentence as the sentence embedding. 5 Benchmark results and discussion We pre-trained four BERT models : BERT-Base ( P ), BERT-Large ( P ), BERT-Base ( P + M ), BERT-Large ( P + M ) on PubMed abstracts only, and the combination of PubMed abstracts and clinical notes, respectively. We present performance on the main benchmark tasks in More de-tailed comparison is shown in the Appendix A. 11https : / / nlp. stanford. edu / projects / glove / Overall, our BERT-Base ( P + M ) that were pre-trained on both PubMed abstract and MIMIC-III achieved the best results across five tasks, even though it is only slightly better than the one pre-trained on PubMed abstracts only. Compared to the tasks in","label":[[302,306,"MODEL"],[740,744,"MODEL"],[915,919,"MODEL"],[1070,1074,"MODEL"],[1084,1088,"MODEL"],[1101,1105,"MODEL"],[1119,1123,"MODEL"],[1140,1144,"MODEL"],[1436,1440,"MODEL"],[425,430,"MODEL"],[621,626,"MODEL"],[1415,1420,"MODEL"],[830,849,"TECHNIQUE"],[898,909,"TECHNIQUE"],[1017,1026,"TECHNIQUE"],[1296,1305,"TECHNIQUE"],[175,181,"DATASET"],[191,197,"DATASET"],[1164,1170,"DATASET"],[1210,1216,"DATASET"],[1486,1492,"DATASET"],[1628,1634,"DATASET"],[200,209,"DATASET"],[1506,1515,"DATASET"],[200,206,"DATASET"],[1506,1512,"DATASET"],[92,96,"DATASET"]],"Comments":[]}
