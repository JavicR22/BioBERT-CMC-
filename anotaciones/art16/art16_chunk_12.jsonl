{"id":12,"text":"may further improve the model â€™ s performance. 6 Conclusion In this study, we introduce BLUE, a collection of resources for evaluating and analyzing biomedical natural language representation models. We find that the BERT models pre-trained on PubMed ab-stracts and clinical notes see better performance than do most state-of-the-art models. Detailed analysis shows that our benchmarking can be used to evaluate the capacity of the models to un-derstand the biomedicine text and, moreover, to shed light on the future directions for developing biomedicine language representations.","label":[[217,221,"MODEL"],[375,387,"TECHNIQUE"],[244,250,"DATASET"]],"Comments":[]}
