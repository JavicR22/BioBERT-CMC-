{"id":3,"text":"as named entity recog-nition and relation extraction. One established trend is a form of word embed-dings that represent the semantic, using high di-mensional vectors ( Chiu, 2016 ; Wang, 2018c ; Zhang, 2019 ). Similar methods also have been derived to improve embeddings of word sequences by introducing sentence embed-dings ( Chen, 2019 ). They always, however, require complicated neural networks to be effec-tively used in downstream applications. Another popular trend, especially in recent years, is the context-dependent representation. Different from word embeddings, it allows the meaning of a word to change according to the con-text in which it is used ( Melamud, 2016 ; Pe-ters, 2017 ; Devlin, 2019 ; Dai, 2019 ). In the scientific domain, Beltagy re-leased SciBERT which is trained on scientific text. In the biomedical domain, BioBERT ( Lee, 2019 ) and BioELMo ( Jin, 2019 ) were pre-trained and applied to several specific tasks. In the clinical domain, Alsentzer released a clinical BERT base model trained on the MIMIC-III database. Most of these works, however, were evaluated on either different datasets or the same dataset with slightly different sizes of examples. This makes it challenging to fairly compare vari-ous language models. Based on these reasons, a standard benchmark-ing is urgently required. Parallel to our work, Lee introduced three tasks : named en-tity recognition, relation extraction, and QA, while Jin introduced NLI in addition to named entity recognition. To this end, we deem that BLUE is different in three ways. First, BLUE is selected to cover a diverse range of text genres, including both biomedical and clinical domains. Second, BLUE goes beyond sentence or sentence pairs by including document classification tasks. Third, BLUE provides a comprehensive suite of codes to reconstruct dataset from scratch without removing any instances. 3 Tasks BLUE contains five tasks with ten corpora that cover a broad range of data quantities and diffi-culties ( Here, we rely on preexisting datasets because they have been widely used by the BioNLP community as","label":[[999,1003,"MODEL"],[770,777,"MODEL"],[841,848,"MODEL"],[33,52,"TECHNIQUE"],[1406,1425,"TECHNIQUE"],[1738,1761,"TECHNIQUE"],[1292,1301,"TECHNIQUE"],[1030,1039,"DATASET"],[1030,1036,"DATASET"]],"Comments":[]}
