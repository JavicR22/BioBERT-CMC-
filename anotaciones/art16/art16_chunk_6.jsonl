{"id":6,"text":"The drug-drug interactions, includ-ing both pharmacokinetic and pharmacodynamic interactions, were annotated by two expert phar-macists with a substantial background in pharma-covigilance. In our benchmark, we use 624 train files and 191 test files to evaluate the performance and report the micro-average F1-score of the four DDI types. ChemProt consists of 1, 820 PubMed abstracts with chemical-protein interactions annotated by domain experts and was used in the BioCre-ative VI text mining chemical-protein interactions shared task ( Krallinger, 2017 ). 6 We use the 4https : / / physionet. org / works / ShAReCLEFeHealth2013 / 5http : / / labda. inf. uc3m. es / ddicorpus 6https : / / biocreative. bioinformatics. udel. edu / news / corpora / standard training and test sets in the ChemProt shared task and evaluate the same five classes : CPR : 3, CPR : 4, CPR : 5, CPR : 6, and CPR : 9. i2b2 2010 shared task collection consists of 170 documents for training and 256 documents for testing, which is the subset of the original dataset ( Uzuner, 2011 ). 7 The dataset was collected from three different hospitals and was annotated by medical practitioners for eight types of relations between problems and treatments. 3. 4 Document multilabel classification The multilabel classification task predicts multiple labels from the texts. HoC ( the Hallmarks of Cancers corpus ) con-sists of 1, 580 PubMed abstracts annotated with ten currently known hallmarks of cancer ( Baker, 2016 ). 8 Annotation was performed at sentence level by an expert with 15 + years of experience in cancer research. We use 315 ( % ) abstracts for testing and the remaining abstracts for train-ing. For the HoC task, we followed the common practice and reported the example-based F1-score on the abstract level ( Zhang and Zhou, 2014 ; Du, 2019 ). 3. 5 Inference task The aim of the inference task is to predict whether","label":[[196,205,"TECHNIQUE"],[306,314,"METRIC"],[1759,1767,"METRIC"],[366,372,"DATASET"],[1399,1405,"DATASET"],[894,898,"DATASET"]],"Comments":[]}
