{"id":12,"text":"potential to lead to more equitable healthcare outcomes in these communities. The development of this NLP system involved consid-eration of two key components : text vectorisation and classification. We compared and evaluated different text vectorisation methods ( TF-IDF, Word2Vec and Doc2Vec ) in combination with classification models ( SVC, KNN and RF ). The results indicated that both the TF-IDF and Doc2Vec text vectorisation models demonstrated the highest performance in terms of AUC when combined with the RF classification model. This suggests that these two vectorisation methods were effective in capturing the relevant information from the clinical notes data and improving the performance of the classification model. In comparison, the SVC and KNN classification models performed worse in terms of AUC when combined with the TF-IDF and Doc2Vec vectorisation methods. The fact that the TF-IDF and Doc2Vec models outper-formed the Word2Vec model in our specific task suggests that performing vectorisation at the document level, as opposed to individual words, is crucial for building a stable and accurate clinical note classifier. The simple mean vector approach, where individual feature vectors from the words in a document are averaged to obtain a document-level representation, used in Word2Vec, was not suitable for the clinical notes in an EHR system. Among the different classification algorithms we eval-uated, the RF classifier demonstrated the best perfor-mance in most of the comparisons. This suggests that the underlying structure of the 300-feature space used in our study was non-linear, and the reduction of variation achieved through ensemble learning in RF contributed to better model training. This finding aligns well with our expectations, considering the complexity of clinical notes data and the relatively large size of the feature vector used in our study. However, we also observed that the recall scores of the RF model were relatively lower compared with precision, indicating that the model had more false negatives. In other words, it tended to miss some positive cases, leading to lower recall rates. The same trend is also observable in other methods, indicating this is not a classifier-specific problem. Instead, this could be due to the imbalanced nature of the dataset, or the specific characteristics of the clinical notes being analysed. Further investigation is needed to understand the reasons behind this observation and identify potential ways to improve the recall per","label":[[273,281,"MODEL"],[945,953,"MODEL"],[1306,1314,"MODEL"],[345,348,"MODEL"],[760,763,"MODEL"],[166,179,"TECHNIQUE"],[1676,1684,"TECHNIQUE"],[265,271,"TECHNIQUE"],[395,401,"TECHNIQUE"],[841,847,"TECHNIQUE"],[901,907,"TECHNIQUE"],[102,105,"TECHNIQUE"],[1999,2008,"METRIC"],[1933,1939,"METRIC"],[2134,2140,"METRIC"],[2517,2523,"METRIC"],[489,492,"METRIC"],[814,817,"METRIC"]],"Comments":[]}
