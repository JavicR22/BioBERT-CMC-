{"id":8,"text":"##6 / bmjhci-2023-100966 on 1 July 2024. Downloaded from https : / / informatics. bmj. com on 11 April 2025 by guest. Protected by copyright, including for uses related to text and data mining, AI training, and similar technologies. 5 Park JI, BMJ Health Care Inform 2024 ; 31 : e100966. Open access classes, aiming to reduce false positives. Recall measures the model ’ s success in identifying actual positives, targeting the reduction of false negatives. AUC reflects the model ’ s ability to differentiate between classes across various thresholds, with higher values denoting greater discrimination. RESULTS Among the 1000 clinical notes we collected, 100 were randomly selected and annotated by a clinical expert, while the remaining 900 were used to build the text corpus. We found 41 positive notes and 59 negative notes from these 100 annotated notes. We divided the anno-tated notes into training and test sets ( using random selection of 70 and 30 notes, respectively ) for modelling. The training set included 27 positive samples, whereas the test set had 14 due to random selection. The anno-tated dataset comprised 41 % of positive labels. The distri-bution of positive labels was 39 % in the training set and 47 % in the test set, closely reflecting the entire dataset. We used the 900 unannotated notes and 70 training notes ( 970 in total ) to build our text corpus in the text vectori-sation model for the final analysis. We identified 13 029 unique words after the stemming process18 among the 970 clinical notes selected for training text vectorisation ( embedding ) model. The mean value was 657. 8, and the SD was 438. 0. The minimum value recorded was 8, and the maximum was 2721. The 25th percentile was 372. 5, the median ( 50th percentile ) was 619. 0 and the 75th percentile was 857. 8. We began by using 970 clinical notes as the corpus input for the TF-IDF model, transforming these notes into vectorised features for training and test sets. The n-gram range was set from 1 – 3 g, resulting in an output feature dimension of 408 791 for the training set. Simi-larly, we used the same corpus to","label":[[1484,1492,"TECHNIQUE"],[1879,1885,"TECHNIQUE"],[343,349,"METRIC"],[458,461,"METRIC"],[688,692,"TECHNOLOGY"]],"Comments":[]}
