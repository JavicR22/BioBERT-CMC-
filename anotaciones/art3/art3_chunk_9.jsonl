{"id":9,"text":"train a Word2Vec word embedding model, following the TF-IDF approach. After training, each word in a note was converted into a vector, and each note was represented by the average of these vectors. For the Doc2Vec approach, we trained a word-embedding model with the same set of clinical notes, treating each note as a document in the Doc2Vec frame-work. This enabled us to infer document vectors for each note, which were then used in training predictive models. Both Word2Vec and Doc2Vec models were assigned a feature size of 2000. In the Word2Vec model, the CBOW approach was preferred over Skip-gram due to its supe-rior performance, while for the Doc2Vec model, we chose the DM model over the DBOW method. A window size of three was selected for both models. The hyperparameters for these models are detailed in Feature selection is a crucial step in machine learning model development, as it helps identify the most relevant features or variables that contribute to a model ’ s predic-tion performance. We employed a selection-by-model approach for feature selection after training the vecto-risers. In this method, an intermediate model is trained to rank the importance of features based on their impact on the overall accuracy or performance of the model. Specifically, we trained an intermediate RF classifier to rank the importance of features based on their contribu-tion to maximising the accuracy of the classifier. The RF classifier was chosen for its ability to handle non-linearity, interactions and most importantly, its ability to provide feature importance estimation. Then we selected the top 300 features ranked by the RF classifier across all text vectorisation models to balance between capturing rele-vant information and avoiding overfitting or issues with high-dimensional data. We performed a random search with fivefold cross-validation to determine the optimal parameters for each model. The hyperparameters used in the random search are listed in The random search keeps the Text vectoriser classifiers hyperparameters for each text vectorisation model Text vectoriser hyperparameters TF-IDF n-gram range : 1 – 3 ; max document frequency : 1. 0 ; min document frequency count : 1 Word2Vec Features size : 2000 ; window size : 3 ; min count : 1 ;","label":[[8,16,"MODEL"],[469,477,"MODEL"],[542,550,"MODEL"],[2212,2220,"MODEL"],[22,37,"MODEL"],[242,257,"MODEL"],[1850,1866,"TECHNIQUE"],[1822,1835,"TECHNIQUE"],[1951,1964,"TECHNIQUE"],[1983,1996,"TECHNIQUE"],[818,835,"TECHNIQUE"],[1056,1073,"TECHNIQUE"],[865,873,"TECHNIQUE"],[53,59,"TECHNIQUE"],[2117,2123,"TECHNIQUE"],[1228,1236,"METRIC"],[1403,1411,"METRIC"],[1159,1163,"APPLICATION"],[1324,1328,"APPLICATION"],[1628,1634,"APPLICATION"]],"Comments":[]}
