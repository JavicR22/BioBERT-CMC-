{"id":5,"text":"domains. The Neuro-Symbolic System for Cancer ( NSSC ), CapMatch, and Perceptive Capsule Network ( PCapN ) exemplify this trend. NSSC integrates symbolic reasoning, LLMs, and deep learning for oncologic entity recognition, while CapMatch combines capsule networks, contrastive learning, and knowl-123 Medical & Biological Engineering & Computing 63 : 749 â€“ 772 751 Motivating example : a clinical note snippet from a breast cancer patient, with correct UMLS terms as the gold standard ( translated into English for clarity ). Both scispaCy and BioFalcon fail to disambiguate and identify the correct terms, illustrating the need for contextual and semantic information to ensure accurate entity recognition in medical texts edge distillation for human activity recognition ( HAR ) from wearable sensors. Similarly, PCapN employs capsule net-works and distillation methods for multivariate time series classification. Despite their different applications-NSSC in medical text, CapMatch in sensor data, and PCapN in time series-each system emphasizes advanced representation learning, knowledge transfer, and context-aware processing, demonstrating the versatility of hybrid AI approaches. Building on these recent advances, this section reviews the stateoftheartinnormalizationoffreetextinbiomedicaldata, focusing on three core areas : named entity recognition-NER ( Section 2. 1 ), entity linking-EL ( Section 2. 2 ), and named entity disambiguation-NED ( Section 2. 3 ). We analyze dif-ferent approaches, including those based on deep learning, knowledge bases ( KB ), symbolic methods, and hybrid AI systems. We also highlight gaps in current approaches, set-ting the stage for further innovation ( Section 2. 4 ). 2. 1 Named entity recognition Named entity recognition ( NER ) is a technique used to classify words in free text into predefined categories such as person names, locations, or medical terms. State-of-the-art NER techniques predominantly rely mainly on deep learning methods, incorporating input representations such as GloVe with BERT document-level embeddings, Cloze-style language model embeddings, or GloVe with aggregated contextual embed","label":[[531,539,"MODEL"],[2037,2042,"MODEL"],[2122,2127,"MODEL"],[2048,2052,"MODEL"],[265,285,"TECHNIQUE"],[1382,1396,"TECHNIQUE"],[175,188,"TECHNIQUE"],[1531,1544,"TECHNIQUE"],[1970,1983,"TECHNIQUE"],[1360,1363,"TECHNIQUE"],[1774,1777,"TECHNIQUE"],[1926,1929,"TECHNIQUE"],[746,772,"APPLICATION"]],"Comments":[]}
