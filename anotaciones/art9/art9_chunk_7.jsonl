{"id":7,"text":"##c scenarios where text closely matches KB entries. This highlights a gap in the development of more robust approaches that can handle unannotated data and spe-cialized domains, such as clinical text, where models such as RoBERTa have shown promise. Future research should focus on bridging the gap between the scalability of deep learning methods and the accuracy of KB-based approaches while improving domain-specific NER capabilities. 2. 2 Entity linking Entity linking ( EL ), also known as entity normalization, is the process of matching entities mentioned in a text with their corresponding entries in a KB. This step typically fol-lows the extraction of entities from the text, where ( entity, label ) tuples are obtained. Given the complexity of natural language-including misspelling and inherent ambiguity-this information must then be normalized. State-of-the-art EL models use neural architectures that have proven superior to classical ML methods. These models can be categorized into four main types : joint mention detection and linking, global models, domain-independent approaches ( including zero-shot methods ), and cross-lingual techniques. Recent advances have shifted towards self-attention architectures such as BERT for mention encoding, with zero-shot methods becoming increasingly prevalent. Cross-encoder architectures, such as E-BERT and BART-based models, have also demonstrated strong per-formance for joint tasks. The EL task has seen applications using KBs, from graph traversal methods to neural network-based approaches. De Cao introduced a generative model that eliminates the need for hard negative sampling during train-ing. These methods improve EL performance by integrating additional knowledge such as entity definitions, entity types, and knowledge graph ( KG ) triples to support training. Despite these advances, models still rely heavily on a fixed number of candidates, approach the problem as a classifica-tion task, and require extensive training data. To mitigate the dependence on labeled datasets, some techniques have begun to use unlabeled corpora. Recent efforts have focused on developing zero-shot models capable of generalizing EL to previously unseen entities. Symbolic approaches in artificial intelligence have also gained popularity. Sakor propose rule-based methods for linking entities in short texts using","label":[[1368,1378,"MODEL"],[223,230,"MODEL"],[1237,1241,"MODEL"],[1359,1363,"MODEL"],[1628,1645,"TECHNIQUE"],[444,458,"TECHNIQUE"],[459,473,"TECHNIQUE"],[1200,1214,"TECHNIQUE"],[327,340,"TECHNIQUE"],[503,516,"TECHNIQUE"],[421,424,"TECHNIQUE"],[357,365,"METRIC"],[1032,1041,"TECHNOLOGY"]],"Comments":[]}
