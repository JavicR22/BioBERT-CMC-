RESEARCH Open Access © The Author(s) 2024. Open Access This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit ​h​t​t​p​:​/​/​c​r​e​a​t​i​ v​e​c​o​m​m​o​n​s​.​o​r​g​/​l​i​c​e​n​s​e​s​/​b​y​-​n​c​-​n​d​/​4​.​0​/​.​ Houston BMC Medical Informatics and Decision Making 24:371 https://doi.org/10.1186/s12911-024-02790-y BMC Medical Informatics and Decision Making *Correspondence: Andrew Houston andrew.houston4@nhs.net Full list of author information is available at the end of the article Abstract Background The digitisation of healthcare records has generated vast amounts of unstructured data, presenting opportunities for improvements in disease diagnosis when clinical coding falls short, such as in the recording of patient symptoms. This study presents an approach using natural language processing to extract clinical concepts from free-text which are used to automatically form diagnostic criteria for lung cancer from unstructured secondary- care data. Methods Patients aged 40 and above who underwent a chest x-ray (CXR) between 2016 and 2022 were included. ICD-10 and unstructured data were pulled from their electronic health records (EHRs) over the preceding 12 months to the CXR. The unstructured data were processed using named entity recognition to extract symptoms, which were mapped to SNOMED-CT codes. Subsumption of features up the SNOMED-CT hierarchy was used to mitigate against sparse features and a frequency-based criteria, combined with univariate logarithmic probabilities, was applied to select candidate features to take forward to the model development phase. A genetic algorithm was employed to identify the most discriminating features to form the diagnostic criteria. Results 75002 patients were included, with 1012 lung cancer diagnoses made within 12 months of the CXR. The best-performing model achieved an AUROC of 0.72. Results showed that an existing ‘disorder of the lung’, such as pneumonia, and a ‘cough’ increased the probability of a lung cancer diagnosis. ‘Anomalies of great vessel’, ‘disorder of the retroperitoneal compartment’ and ‘context-dependent findings’, such as pain, statistically reduced the risk of lung cancer, making other diagnoses more likely. The performance of the developed model was compared to the existing cancer risk scores, demonstrating superior performance. Conclusions The proposed methods demonstrated success in leveraging unstructured secondary-care data to derive diagnostic criteria for lung cancer, outperforming existing risk tools. These advancements show potential for enhancing patient care and results. However, it is essential to tackle specific limitations by integrating primary care data to ensure a more thorough and unbiased development of diagnostic criteria. Moreover, the study highlights Automated derivation of diagnostic criteria for lung cancer using natural language processing on electronic health records: a pilot study Andrew Houston1,2*, Sophie Williams1,2, William Ricketts3, Charles Gutteridge1, Chris Tackaberry4 and John Conibear5 Page 2 of 10 Houston BMC Medical Informatics and Decision Making 24:371 Background Lung cancer stands as one of the most common and seri­ ous types of cancer, ranking 2nd in terms of new cases and 1st in terms of mortalities, according to global statis­ tics from 2020 . The most recent statistics show that, in England, only 29.4% of lung cancer cases are identified at stages 1 and 2 , underscoring the critical need for improved diagnostic criteria and detection methods to enhance the chances of successful treatment and reduce the burden of this disease on patients and healthcare sys­ tems. Recognising this urgency, the NHS has a long-term plan to diagnose 75% of all lung cancers at stages 1 and 2 by 2028, aiming to significantly improve early detection rates and patient outcomes. Early diagnosis is imperative given the aggressive nature of lung cancer, with delays in detection resulting in patients presenting with more advanced stages of the disease. Recent data published by the Office for National Statistics and Public Health England showed the 5-year survival rate among patients diagnosed with stage 1 lung cancer was 56.6%, with this figure reducing to only 2.9% among those diagnosed with stage 4 disease . Addi­ tionally, precise diagnostic criteria play a pivotal role in distinguishing lung cancer from a spectrum of cardiotho­ racic and respiratory conditions that may exhibit similar symptoms. With that said, to ensure the cost-effective­ ness and cost-benefit of targeted interventions aimed at improving the diagnosis of lung cancer, judicious alloca­ tion of resources is required . Electronic health records (EHRs) have revolutionized clinical research by offering a vast and comprehensive repository of patient information. Records encompass a range of data, including patient demographics, medi­ cal history, laboratory results, medication prescriptions, and procedure information. Such extensive and struc­ tured data enable researchers to conduct large-scale, population-based studies, aiding in the identification of trends , risk factors [6–8], and treatment outcomes . However, a significant limitation of EHRs per­ tains to accuracy and completeness, particularly among symptoms and diagnosis data. Symptoms and diagnoses are often documented in unstructured free-text clinical notes, requiring manual coding into clinical ontologies such as ICD-10 and SNOMED-CT. The process of clini­ cal coding can introduce inaccuracies and ‘missingness’ in the data, posing considerable challenges for clinical research . Considering these challenges, tech­ niques such as natural language processing (NLP) offer valuable solutions for not only mitigating the limitations of structured data but also unlocking valuable insights that may be exclusive to free-text narratives of patient encounters. Natural Language Processing (NLP) has gained util­ ity in extracting and analysing information in Electronic Health Records (EHRs). Koleck conducted a literature review, finding 27 relevant studies using NLP to analyse symptoms in EHR narratives . NLP has been used for auditing discharge reports , predicting read­ missions , and aiding in diagnosis [16–18]. Weissman used NLP to classify discharge documents based on critical illness-related keywords with high accu­ racy . Greenwald developed an NLP tool to extract readmission-related concepts and achieved comparable performance to existing prediction mod­ els . In oncology, NLP extracted features from CT reports for predicting lymph node metastasis in non- small cell lung cancer (NSCLC) with competitive perfor­ mance . Despite its potential, there’s a gap in applying NLP to oncology symptoms, highlighting an opportunity for further research . While NLP has demonstrated its effectiveness in vari­ ous healthcare applications, there is a growing recogni­ tion of the advantages of extracting ontological concepts rather than use-case-specific concepts . This approach provides a more generalised framework for understanding and organising medical information, contributing to interoperability and facilitating the linkage with already coded, structured, clinical data found in the EHR. This transition to ontological con­ cept extraction aligns with the broader adoption of stan­ dardised medical terminologies like SNOMED CT, which play an important role in structuring and organizing clin­ ical data for improved healthcare decision-making and research. From a machine learning perspective, extraction of concepts from a hierarchical ontology offers a crucial advantage, enabling the retention of valuable informa­ tion, even when a patient reports rarer or more spe­ cific symptoms. For instance, when a patient mentions a symptom like a ‘chesty cough’, machine learning sys­ tems can link it to a higher-level concept in the ontology, such as “cough.” This hierarchical relationship allows the model to preserve the broader context and meaning of the symptom, preventing the loss of nuanced informa­ tion that might occur in non-hierarchical concept lists, where rare features might otherwise be removed. Failure the importance of contextualising SNOMED-CT concepts into meaningful terminology that resonates with clinicians, facilitating a clearer and more tangible understanding of the criteria applied. Keywords Electronic health records, Natural language processing, Cancer, Diagnostics, SNOMED-CT, Machine learning, Genetic optimisation Page 3 of 10 Houston BMC Medical Informatics and Decision Making 24:371 to account for such sparsity could result in poor or unre­ liable classification performance . Given the promise of NLP for the accurate extraction of relevant features, at scale, this study applies NLP to extract SNOMED-CT concepts from free-text notes, applies subsumption to elevate rarer symptoms up the ontological hierarchy, then feeds the final feature set into a machine learning framework to train a model to discriminate lung cancer from other diseases. Further­ more, this study provides an exploration into how feature weights might be affected by demographic information like age, sex and ethnicity. Methodology Eligibility Data were extracted from the Barts Health NHS Trust Data Warehouse for all patients meeting the follow­ ing eligibility criteria: Patients referred for a chest x-ray (CXR), aged 40 years or older at the point of referral, dur­ ing two time periods between 01 Jan 2016 and 31 Dec 2019 or 01 Jan 2022 and 31 Dec 2022 were eligible for inclusion. The time window of 01 Jan 2020–31 Dec 2021 was not considered due to deviations from the typical cancer care-pathways as a result of the COVID-19 pan­ demic. Patients who had opted out of their data being used for research, those without medical notes beyond four years from the original x-ray, unless a second con­ firmatory x-ray within four years ruled out lung cancer, and patients with an existing or historical diagnosis of any cancer were excluded from participation in the study. Data sources All free-text data contained in the secondary care EHR system, from one year prior to the date of the first chest X-ray, were extracted and combined with demo­ graphic information, including Age, Sex and Ethnicity, and ICD-10 data from the same time period. Addition­ ally, diagnostic data in the form of ICD-10 codes and the Somerset Cancer Registry were extracted for the subse­ quent four years post-CXR, or up to the maximum avail­ able timepoint. To determine the ground truth, a patient was labelled as having lung cancer if a diagnosis was recorded in the Somerset Cancer Registry, or an ICD-10 code of C34 (Malignant neoplasm of bronchus and lung) was present in the patient’s EHR post-CXR. Considering the potential delays in diagnoses, post-CXR, and the delays in upload­ ing this information onto the electronic health records system, model training was performed iteratively, each time re-labelling the ground truth to consider an addi­ tional month of diagnoses. The iterative process was per­ formed first considering only patients diagnosed with lung cancer within the subsequent month following their CXR, continuing to add more patients until 12-months post-CXR. Instances of lung cancer diagnoses over time the respective model performance is presented in Feature extraction To extract structured information from the free-text data, named entity recognition (NER) was performed using the NLP software, CLiX (Clinithink Ltd., London, UK). CLiX was chosen due to its demonstrated effectiveness in extracting clinically relevant phenotypic data from electronic health records, as evidenced by successful applications in similar studies such as the identification of sub-phenotypes of diabetic kidney disease and the automated prioritisation of patients for whole genome sequencing . The free-text was queried against two resource sets, a ‘Core-Problems’ list containing common clinical symptoms and diagnoses, and the Human Phe­ notype Ontology. The top 100 clinical features for each resource set are presented in the supplementary file. The number of diagnoses occurring at each monthly interval, for the subsequent 12 months post-CXR. (b) The mean AUROC of the three tested models across each monthly interval, demonstrating the performance stabilisation and plateau from month five onwards. The shaded area indicates the standard deviation of the AUROC across the cross-validation folds Page 4 of 10 Houston BMC Medical Informatics and Decision Making 24:371 Feature Engineering To handle missing data, sex and ethnicity were imputed using the most common category. Symptom data were binary, and an assumption was made that if a diagnosis or symptom was not found in either the structured ICD-10 data or identified by the NLP algorithm, the patient did not have the diagnosis or symptom. To ensure a harmonised dataset, all features were mapped to the SNOMED-CT ontology. To address the sparseness of features in the lower levels of the SNOMED-CT hierarchy, we employed a subsumption process to generate and maintain features at higher levels of the hierarchy, ensuring the inclusion of all subordinate features. The code for the subsumption method is freely available at: ​h​t​t​p​s​:​/​/​g​i​t​h​u​b​.​c​o​m​/​a​n​d​r​e​w​h​o​u​s​t​o​n​1​1​3​/​s​n​o​ m​e​d​F​e​a​t​u​r​e​S​e​l​e​c​t​i​o​n​.​ Feature selection Given the high dimensionality, with the number of symp­ tom features exceeding 12,000, the dataset could not be analysed statistically. Instead, a genetic approach was taken. First, symptom features were removed where less than 0.5% of all patients or less than 5% of lung cancer patients had the symptom documented in their notes. Thereafter, the remaining features were ranked according to their Bayesian importance value, calculated as: IMPTNB = |log (p (xi = 1|yj = 1)) −log (p (xi = 1|yj = 0)) | where xi and yj are 1-dimensional binary arrays indi­ cating the presence of featurei and diagnosis j for each patient. Following the ranking of all features, starting from the lowest ranking symptom, symptoms were removed should they have a Jaccard coefficient greater than 0.8. Thereafter, the remaining symptoms were input into a tabu asexual genetic algorithm (TAGA) , configured to select the feature set which maximises the area under the receiver operating characteristic curve (AUROC). TAGA was tasked with returning λ features, where λ is a number between 5 and 20. The rationale for capping the number of features included in a model at 20 was to ensure the interpretability of the final diagnostic criteria and to prevent overfitting. Model development and evaluation 20% of the data was held out of the model development process and used as a test set, with the remaining 80% being used for training and validation. For each model, a 5-fold cross-validation process was applied to select the most relevant features and identify the appropriate hyperparameters for the model, following which per­ formance was examined using the test set. Recognising that there are vastly more non-lung cancer patients in the dataset than lung cancer patients, there is the likeli­ hood that the model may not predict any patients as hav­ ing lung cancer to achieve a highly accurate performance. Therefore, in training the model, cost-sensitive learning was employed to assign a higher penalty to misclassify­ ing lung cancer patients compared to misclassifying non- lung cancer patients. The performance of the trained models was assessed using the following diagnostic test characteristics; accuracy, sensitivity, and specificity, in addition to the calculation of the AUROC, with AUROC acting as the primary evaluation measure. Given the highly imbalanced nature of the task, balanced accuracy was also calculated, with balanced accuracy defined as the sum of sensitivity and specificity divided by two. This study considered the following classification mod­ els: Logistic Regression, Mixed Naïve Bayes, and Deci­ sion Trees. The rationale for the selection of these models lies in their interpretability and ease of application. Comparison with existing risk tools To determine whether the proposed method improves the diagnosis of lung cancer beyond that of existing methods that make use of similar features, a compari­ son with existing risk tools was performed. The pro­ posed method was compared against the lung cancer component of the QCancer score and the lung cancer-related risk assessment tools listed on the Cancer Research UK website . In applying the QCancer score, the publicly avail­ able weights were used, and the score calculated on the same test set used for all previous comparisons. The risk assessment tools (RATs) of Hamilton are solely a set of feature combinations and their associated positive predictive values. Therefore, to apply the RATs to the data used in this body of work, a logistic regres­ sion model was trained for each feature combination, using the training set used for all previous experiments, returning the probability of lung cancer for each patient in the test set. Thereafter, the highest probability of all feature combinations was regarded as the final predic­ tion for each patient. As before, the AUROC was used to compare the models, and DeLong’s test was applied to statistically compare the ROC curves . Bonferroni correction was used to account for multiple comparisons. Results Demographic information In total, 75,002 patients (35628 female) were included in this study. The study population had a mean age of 63 years 14 years. 36,123 identified as ‘White’, 20,219 iden­ tified as ‘Asian’, 7851 identified as ‘Black’, 3330 identified as ‘Other’ and 835 identified as ‘Mixed Ethnicity’. Data for sex was missing in two patients, and ethnicity data was missing in 6644 patients, both of which were imputed. Page 5 of 10 Houston BMC Medical Informatics and Decision Making 24:371 In total, over the 12-month observation period after the first CXR, a total of 1012 lung cancer diagnoses were made. The occurrence of lung cancer at each monthly increment are shown in Also, plotted are the number of diagnoses made following a repeat scan. The total number of diagnoses following the first scan pla­ teaued four months post-CXR, with additional diagnoses after which time being made only after a further CXR. Aside from lung cancer, other common respiratory diag­ noses in the dataset included: COPD (n = 1883), atelecta­ sis (n = 2432) and pneumonia (n = 398). Risk-score performance characteristics shows the performance of each of the three models, in terms of AUROC, across all 12 time intervals. The performance of the logistic regression model signifi­ cantly outperformed the other two models, in terms of absolute performance but also model stability, denoted by the reduced standard deviation of AUROC. Of note, the performance of all models was less stable in the first five months, highlighting the likelihood of poorer class labelling resulting from a delay in diagnoses being uploaded to the EHRs. Considering the stabilisation in performance at five months, coupled with the plateau in diagnoses without additional scans, to strike the bal­ ance between the highest quality labelling and stable model performance, the ground truth labels established at 5-months were used for all future experiments. Influence of age, sex and ethnicity on risk-score performance shows the performance of the model solely using the symptoms found in the EHR of the patient, then with the inclusion of demographic data. The inclusion of age and ethnicity was shown to improve the diagnostic performance of the model, increasing AUROC to 0.69 and 0.67, respectively. Gender did not improve model performance in isolation. The inclusion of age, gen­ der and ethnicity improved model performance across all metrics resulting in an AUROC of 0.72, with an associated sensitivity and specificity of 0.69 and 0.67, respectively. Feature importance To understand how each predictor influences the predic­ tion of lung cancer, SHAP (Shapley Additive Explana­ tions) values were calculated ( The most influential feature was age, with older individuals exhibiting a sig­ nificant increase in the model’s output towards predict­ ing lung cancer. Additionally, the presence of an ‘existing disorder of the lung’ was found to positively impact the prediction. Notably, individuals of white ethnicity had the greatest influence on the model outputs, increas­ ing the SHAP value towards the prediction of lung can­ cer, although all ethnicities displayed varying degrees of impact toward a positive diagnosis. Males had an increased SHAP value, contributing to the prediction. Conversely, the presence of a ‘congenital anomaly of a great vessel’ and ‘disorders of the retroperitoneal com­ partment’ reduced the SHAP value. Context-dependent factors, such as pain, bleeding, and arthropathy, also reduced the SHAP value, making a prediction of lung cancer less likely. Finally, the presence of a cough was found to increase the SHAP value, further emphasising its relevance in the prediction of lung cancer. Due to the relevancy of ethnicity variables ranking highly in terms of feature importance, an additional anal­ ysis was carried out to understand how performance may fluctuate regarding different ethnic groups. Results are presented in and highlight the need for greater Performance characteristics of the logistic regression model on the test set, when each combination of the demographic features is incorporated. Values in brackets indicate the mean and standard deviation of the cross-validation performed on the training set Input Features Accuracy Balanced Accuracy AUROC Sensitivity Specificity Symptoms Only 0.78 (0.77 0.02) 0.59 (0.6 0.01) 0.63 (0.63 0.02) 0.41 (0.44 0.03) 0.78 (0.77 0.02) Symptoms and Age 0.66 (0.66 0.00) 0.64 (0.66 0.01) 0.69 (0.71 0.01) 0.62 (0.66 0.03) 0.66 (0.66 0.00) Symptoms and Gender 0.78 (0.73 0.08) 0.59 (0.6 0.02) 0.64 (0.64 0.03) 0.41 (0.46 0.07) 0.78 (0.74 0.08) Symptoms and Ethnicity 0.54 (0.55 0.02) 0.61 (0.61 0.02) 0.67 (0.66 0.02) 0.69 (0.68 0.06) 0.54 (0.55 0.02) Symptoms, Age and Gender 0.66 (0.66 0.00) 0.66 (0.67 0.01) 0.7 (0.72 0.01) 0.66 (0.67 0.02) 0.66 (0.66 0.00) Symptoms, Age and Ethnicity 0.66 (0.66 0.00) 0.67 (0.66 0.01) 0.71 (0.72 0.01) 0.68 (0.67 0.02) 0.66 (0.66 0.00) Symptoms, Gender and Ethnicity 0.66 (0.63 0.04) 0.6 (0.61 0.02) 0.68 (0.67 0.02) 0.54 (0.59 0.04) 0.66 (0.63 0.04) Symptoms, Age, Gender and Ethnicity 0.66 (0.66 0.00) 0.67 (0.67 0.02) 0.72 (0.72 0.01) 0.69 (0.69 0.03) 0.66 (0.66 0.00) Page 6 of 10 Houston BMC Medical Informatics and Decision Making 24:371 consideration of bias within future iterations of model development, given the poor performance among Asian and Mixed cohorts. Given the high-level nature of several the features, due to the subsumption process applied, an exploration into what symptoms or co-morbidities comprised such fea­ tures was performed. shows each of the selected features, and some of the most prominent features which comprise them. Comparison of the proposed approach with other cancer risk tools shows the receiver operating characteris­ tic curve of the model produced using the methods described in this paper, the QCancer score , and the lung cancer related risk assessment tools listed on the Cancer Research UK website . As previ­ ously reported, the proposed methods resulted in an AUROC of 0.72. The application of the QCancer calcula­ tor to the test set used throughout this paper resulted in an AUROC of 0.67 and the methods of Hamilton achieved and AUROC of 0.55. Results of statistical analysis, using DeLong’s tests, found that the proposed A subgroup analysis of model performance with respect to ethnicity Group N Accuracy Balanced Accuracy Sensitivity Specificity AUROC White 7316 0.50 0.62 0.75 0.50 0.65 Asian 4008 0.90 0.57 0.23 0.91 0.72 Black 1526 0.77 0.74 0.70 0.77 0.78 Other 681 0.72 0.76 0.80 0.72 0.85 Mixed 168 0.86 0.43 0.00 0.86 0.37 A summary plot of the SHAP values denoting the impact of each feature in the best performing model, on the prediction of lung cancer. Shading of each datapoint indicates the value of the feature. For all binary features, except age, a red value denotes a “true” value and blue denotes a false value. For age, the bluer a datapoint reflect a younger age, and the redder a data point, the older the patient Page 7 of 10 Houston BMC Medical Informatics and Decision Making 24:371 approach significantly improved upon the QCancer score (p = 0.015) and Hamilton (p < 0.001). Discussion This work aimed to explore the use of NLP for the extrac­ tion of SNOMED-CT concepts from unstructured clini­ cal free-text, coupled with subsumption techniques to address the challenges posed by sparse features in high- dimensional datasets. Leveraging genetic optimisation and machine learning, the generated dataset was used to develop a predictive model for lung cancer diagnosis. Model development resulted in a classifier with stable performance characterised by low standard deviations between the cross-validation folds and an AUROC of 0.72. Additionally, the model offers a balanced trade-off between sensitivity and specificity with values of 0.69 and 0.66, respectively. Notably, our proposed methodol­ ogy outperforms both the QCancer calculator and the methods introduced by Hamilton , highlighting the promise NLP and machine learning approaches could have for the curation of rich datasets and the development of robust predictive models in the field of lung cancer risk assessment. The incorporation of subsumption techniques helped mitigate the challenges posed by sparse features within our predictive model. By hierarchically organising and abstracting SNOMED-CT concepts, subsumption allowed us to identify broader, higher-level categories that encapsulate a range of related clinical terms. This not only alleviated the risk of overfitting and unreliable Visualisation of common concepts subsumed into higher level concepts in the SNOMED-CT hierarchy Page 8 of 10 Houston BMC Medical Informatics and Decision Making 24:371 performance, a common concern in models trained on sparse data , but enhanced the generalisability of our model. However, the introduction of more abstract, top-level features meant that the final model was rooted in a level of granularity less commonly used in routine clinical practice. This has important implications for the practical translation and messaging of the model, high­ lighting the need for a clear and effective strategy to bridge the gap between the model’s output, which oper­ ates at a higher conceptual level, and the clinical realities on the ground, which makes use of specific and well- established terminology. The primary function of our model is to evaluate the likelihood of a positive lung cancer diagnosis when a patient enters the clinical pathway for this purpose. While this is a valuable step in enhancing early diagno­ sis and intervention, the success of a diagnostic tool is often measured by its ability to identify patients even before they enter the diagnostic pathway , ultimately achieving a significant stage shift in the diagnostic pro­ cess which is associated with improved mortality rates . The primary limitation of this study is its reliance on secondary care data, which did not provide sufficient longitudinal information to facilitate such an analysis. It is essential to recognise that most patient interactions with the healthcare system before a lung cancer diagnosis occur in primary care facilities, where symptoms are first reported and initial evaluations are made [34–37]. The absence of primary care data in our study thus limits the real-world applicability of the developed methods and highlights the need for future efforts to incorporate pri­ mary care data to truly impact early detection and diag­ nosis in clinical practice. A core limitation relates to documentation bias. Although purely data-driven methods were employed to derive the features predictive of lung cancer, most patients had only one document before their CXR, a referral letter. Therefore, we must consider the possibil­ ity that the referring clinician may only include symp­ toms that they perceive to be relevant to the suspected diagnosis for which the scan is required, omitting other symptoms which may prove predictive. Such a limitation will often be present in such predictive modelling stud­ ies. However, if each patient were to have more clinical notes before the suspecting of lung cancer the effect of such bias may be reduced. Clinically, the absence of staging data restricts our insight into the model’s capacity to identify lung cancer at an early stage, which is crucial for understanding the impact of the predictions on patient outcomes. Addi­ tionally, the NER methods employed were not trained to extract genetic variants from pathology reports, spe­ cifically lung-cancer specific risk loci, which could fur­ ther improve the performance of the model . Beyond model development, the lack of other data sources restricts the comparisons that can be drawn to more con­ temporary methods. Many of the latest lung cancer pre­ diction models use data sources beyond symptoms and demographics, such as laboratory test results , imag­ ing , and genetic testing . Without access to such data, it is difficult to directly compare our model to such models. Future studies with access to more comprehen­ sive datasets could help address these limitations and further enhance the efficacy and generalisability of the developed predictive model. Conclusions This research highlights the potential of combining natural language processing and machine learning tech­ niques to enhance diagnostic criteria for lung cancer using unstructured healthcare data. The study’s key find­ ings include the successful identification of discriminat­ ing features associated with lung cancer diagnosis and achieving promising AUROC scores which outperform other comparable risk assessment tools. Such advance­ ments hold promise for improving patient care and out­ comes, albeit with a need to address certain limitations through the incorporation of primary care data for more comprehensive and unbiased criteria development. Abbreviations AUROC Area Under the Receiver Operating Characteristic curve COPD Chronic Obstructive Pulmonary Disease CT Computed Tomography CXR Chest X-ray EHR Electronic Health Record ICD 10-International Classification of Diseases NER Named Entity Recognition NHS National Health Service NLP Natural Language Processing NSCLC Non-Small Cell Lung Cancer SHAP Shapley Additive Explanations Receiver operating characteristic curves for the proposed method, QCancer and methods of Hamilton , when applied to the test set used in this study Page 9 of 10 Houston BMC Medical Informatics and Decision Making 24:371 SNOMED CT-Systematized Nomenclature of Medicine-Clinical Terms TAGA Tabu Asexual Genetic Algorithm Supplementary Information The online version contains supplementary material available at ​h​t​t​p​s​:​/​/​d​o​i​.​o​r​ g​/​1​0​.​1​1​8​6​/​s​1​2​9​1​1​-​0​2​4​-​0​2​7​9​0​-​y​.​ Supplementary Material 1