hand, it takes more than 20 epochs for BioBERT to reach its highest performance on the NER datasets. 4. 3 Experimental results The results of NER are shown in First, we observe that BERT, which was pre - trained on only the general domain corpus is quite effective, but the micro averaged F1 score of BERT was lower ( 2. 01 lower ) than that of the state - of - the - art models. On the other hand, BioBERT achieves higher scores than BERT on all the data - sets. BioBERT outperformed the state - of - the - art models on six out of nine datasets, and BioBERT v1. 1 ( þ PubMed ) outperformed the state - of - the - art models by 0. 62 in terms of micro averaged F1 score. The relatively low scores on the LINNAEUS dataset can be attrib - uted to the following : ( i ) the lack of a silver - standard dataset for training previous state - of - the - art models and ( ii ) different training / test set splits used in previous work ( Giorgi and Bader, 2018 ), which were unavailable. The RE results of each model are shown in BERT achieved better performance than the state - of - the - art model on the CHEMPROT dataset, which demonstrates its effectiveness in RE. On average ( micro ), BioBERT v1. 0 ( þ PubMed ) obtained a higher F1 score ( 2. 80 higher ) than the state - of - the - art models. Also, BioBERT achieved the highest F1 scores on 2 out of 3 biomedical datasets. The QA results are shown in We micro averaged the best scores of the state - of - the - art models from each batch. BERT obtained a higher micro averaged MRR score ( 7. 0 higher ) than the state - of - the - art models. All versions of BioBERT significantly out - performed BERT and the state - of - the - art models, and in particular, BioBERT v1. 1 ( þ PubMed ) obtained a strict accuracy of 38. 77, a le - nient accuracy of 53. 81 and a mean reciprocal rank score of 44. 77, all of which were micro averaged. On all the bio