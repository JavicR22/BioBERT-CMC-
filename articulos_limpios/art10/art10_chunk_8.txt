reciprocal rank. 4 Results 4. 1 Datasets The statistics of biomedical NER datasets are listed in We used the pre - processed versions of all the NER datasets provided by Wang except the 2010 i2b2 / VA, JNLPBA and Species - 800 datasets. The pre - processed NCBI Disease dataset has fewer annotations than the original dataset due to the removal of duplicate articles from its training set. We used the CoNLL format ( https : / / github. com / spyysalo / standoff2conll ) for pre - processing the 2010 i2b2 / VA and JNLPBA datasets. The Species - 800 dataset was pre - processed and split based on the dataset of Pyysalo ( https : / / github. com / spyysalo / s800 ). We did not use alternate annotations for the BC2GM dataset, and all NER evaluations are based on entity - level exact matches. Note that although there are several other recently introduced high quality biomedical NER datasets ( Mohan and Li, 2019 ), we use datasets that are frequently used by many biomedical NLP researchers, which makes it much easier to compare our work with theirs. The RE datasets contain gene – disease relations and pro - tein – chemical relations ( Pre - processed GAD and EU - ADR datasets are available with our provided codes. For the CHEMPROT dataset, we used the same pre - processing procedure described in Lim and Kang. We used the BioASQ factoid datasets, which can be converted into the same format as the SQuAD dataset ( We used full abstracts ( PMIDs ) and related questions and answers provided by the BioASQ organizers. We have made the pre - processed BioASQ datasets publicly avail - able. For all the datasets, we used the same dataset splits used in pre - vious works ( Lim and Kang, 2018 ; Tsatsaronis, 2015 ; Wang, 2018 ) for a fair evaluation ; however, the splits of LINAAEUS and Species - 800 could not be found from Giorgi and Bader and may be different. Like previous work ( Bhasuran and Natarajan, 2018 ), we reported the performance of 10 - fold cross - validation on datasets that do