may further improve the model ’ s performance. 6 Conclusion In this study, we introduce BLUE, a collection of resources for evaluating and analyzing biomedical natural language representation models. We ﬁnd that the BERT models pre - trained on PubMed ab - stracts and clinical notes see better performance than do most state - of - the - art models. Detailed analysis shows that our benchmarking can be used to evaluate the capacity of the models to un - derstand the biomedicine text and, moreover, to shed light on the future directions for developing biomedicine language representations.