- cant CPU power and memory for pre - processing tasks ). This is not including any time required to download or setup MIMIC or to train any ﬁ - nal downstream tasks. 18 days of continuous run - time is a signiﬁcant investment and may be be - yond the reach of some labs or institutions. This is precisely why we believe that releasing our pre - trained model will be useful to the community. 3. 3 Tasks The Clinical BERT and Clinical BioBERT mod - els were applied to the MedNLI natural lan - guage inference task ( Romanov and Shivade, 2018 ) and four i2b2 named entity recognition ( NER ) tasks, all in IOB format ( Ramshaw and Marcus, 1995 ) : i2b2 2006 1B de - identiﬁcation ( Uzuner, 2007 ), i2b2 2010 concept extrac - tion ( Uzuner, 2011 ), i2b2 2012 entity extrac - Dataset Metric Dim # Sentences Train Dev Test MedNLI Accuracy 3 11232 1395 1422 i2b2 2006 Exact F1 17 44392 5547 18095 i2b2 2010 Exact F1 7 14504 1809 27624 i2b2 2012 Exact F1 13 6624 820 5664 i2b2 2014 Exact F1 43 45232 5648 32586 Task dataset evaluation metrics, output dimen - sionality, and train / dev / test dataset sizes ( in number of sentences ). Exact F1 requires that the text span and la - bel be an exact match to be considered correct. tion challenge ( Sun, 2013a, b ), i2b2 2014 7A de - identiﬁcation challenge ( Stubbs and Uzuner, 2015 ; Stubbs, 2015 ). Details of the IOB for - mat can be seen in the appendix, section C. All task dataset sizes, evaluation metrics, and number of classes are shown in Note that our two de - identiﬁcation ( de - ID ) datasets present synthetically - masked PHI in their texts — e. g., they replace instances of real names, hospitals, etc., with synthetic, but consistent and realistic, names, hospitals, etc. As