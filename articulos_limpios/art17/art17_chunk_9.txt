each from 3 categories under BioBERT and Clinical BERT. These lists suggest that Clinical BERT re - tains greater cohesion around medical or clinic - operations relevant terms than does BioBERT. For example, the word “ Discharge ” is most closely associated with “ admission, ” “ wave, ” and “ sight ” under BioBERT, yet only the former seems rele - vant to clinical operations. In contrast, under Clin - ical BERT, the associated words all are meaningful in a clinical operations context. Limitations & Future Work This work has several notable limitations. First, we do not ex - periment with any more advanced model architec - tures atop our embeddings. This likely hurts our performance. Second, MIMIC only contains notes from the intensive care unit of a single healthcare institution ( BIDMC ). Differences in care practices across institutions are signiﬁcant, and using notes from multiple institutions could offer signiﬁcant gains. Lastly, our model shows no improvements for either de - ID task we explored. If our hypoth - esis is correct as to its cause, a possible solution could entail introducing synthetic de - ID into the source clinical text and using that as the source for de - ID tasks going forward. 5 Conclusion In this work, we pretrain and release clinically ori - ented BERT models, some trained solely on clini - cal text, and others ﬁne - tuned atop BioBERT. We ﬁnd robust evidence that our clinical embeddings are superior to general domain or BioBERT spe - ciﬁc embeddings for non de - ID tasks, and that us - ing note - type speciﬁc corpora can induce further selective performance beneﬁts. To the best of our knowledge, our work is the ﬁrst to release clini - cally trained BERT models. Our hope is that all clinical NLP researchers will be able to beneﬁt from these embeddings without the necessity of the signiﬁcant computational resources required to train these models over the MIMIC corpus. 6