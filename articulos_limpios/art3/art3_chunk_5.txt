preprocessing to ensure they were clean and normalised. Following preprocessing, the cleaned text corpus was used for text vectorisation. Addi - tionally, we randomly sampled notes and had them anno - tated by clinical experts. After annotation, the texts were mapped into a feature vector space ( vectorisation ). We then selected the most impactful features and reduced the feature dimension ( feature selection ) to train a conventional classifier and predict the outcome using this feature vector. Subsequent sections provide a detailed description of each step involved. Data preprocessing and annotation To prepare text data for the NLP process, it must undergo preprocessing. This involves standard NLP cleaning tech - niques such as removing numbers, special characters and duplicated words ; performing word tokenisation ; removing stop words and applying stemming. 17 Once cleaned, these text data serve as a corpus to train a vectori - sation model that converts input text into numerical form ( feature vector ). This vectorisation can proceed without explicit document annotation, relying on the text corpus of the clinical notes. In contrast, expert annotations are crucial for the classification phase, making it a supervised learning task. Notes were labelled as positive if they refer - enced side effects or symptoms of breast cancer treat - ment, adhering to guidelines from the American Cancer Society and American Society of Clinical Oncology. 18 A clinical expert annotated 100 notes, which were randomly selected from the original texts. Subsequently, the anno - tated data were divided into training and test sets using a 7 : 3 ratio. BMJ Health & Care Informatics : first published as 10. 1136 / bmjhci - 2023 - 100966 on 1 July 2024. Downloaded from https : / / informatics. bmj. com on 11 April 2025 by guest. Protected by copyright, including for uses related to text and data mining, AI training, and similar technologies. 3 Park JI, BMJ Health Care Inform 2024 ; 31 : e100966. Open access Text vectorisation The texts were converted into a set of numerical values — a vector that represents a given text. We used three different vectorisation approaches — term frequency - inverse document frequency ( TF - IDF ), 19 Word2Vec20 and Doc2Vec21 — and compared their performance with different predict