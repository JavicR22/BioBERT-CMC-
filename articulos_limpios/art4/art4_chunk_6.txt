papers that are related to LLMs after the release of ChatGPT in As discussed before, language model is not a new tech - nical concept specially for LLMs, but has evolved with the advance of artificial intelligence over the decades. Early lan - guage models mainly aim to model and generate text data, while latest language models ( e. g., GPT - 4 ) focus on complex task solving. From language modeling to task solving, it is an important leap in scientific thinking, which is the key to understand the development of language models in the re - search history. From the perspective of task solving, the four generations of language models have exhibited different lev - els of model capacities. In we describe the evolu - tion process of language models in terms of the task solving capacity. At first, statistical language models mainly assisted in some specific tasks ( e. g., retrieval or speech tasks ), in which the predicted or estimated probabilities can enhance the performance of task - specific approaches. Subsequently, neural language models focused on learning task - agnostic representations ( e. g., features ), aiming to reduce the efforts for human feature engineering. Furthermore, pre - trained language models learned context - aware representations that can be optimized according to downstream tasks. For the latest generation of language model, LLMs are enhanced by exploring the scaling effect on model capacity, which can be considered as general - purpose task solvers. To summarize, in the evolution process, the task scope that can be solved by language models have been greatly extended, and the task performance attained by language models have been significantly enhanced. In the existing literature, PLMs have been widely dis - cussed and surveyed [ 36 â€“ 39 ], while LLMs are seldom re - viewed in a systematic way. To motivate our survey, we first highlight three major differences between LLMs and PLMs. First, LLMs display some surprising emergent abilities that may not be observed in previous smaller PLMs. These abili - ties are key to the performance of language models on com - plex tasks, making AI algorithms unprecedently powerful and effective. Second, LLMs would revolutionize the way that humans develop and use AI algorithms. Unlike small PLMs, the major approach to accessing LLMs is through 1. Note that a LLM is not necessarily more capable than a small PLM, and emerge